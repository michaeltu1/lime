{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.applications import inception_v3 as inc_net\n",
    "from keras.preprocessing import image\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.segmentation import find_boundaries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "try:\n",
    "    import lime\n",
    "except:\n",
    "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
    "    import lime\n",
    "from lime import lime_image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_label = {1: 'airplane', 2: 'bird', 3: 'car', 4: 'cat', 5: 'deer', \n",
    "                   6: 'dog', 7: 'horse', 8: 'monkey', 9: 'ship', 10: 'truck'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inception\n",
    "Here we create a standard InceptionV3 pretrained model and use it on images by first preprocessing them with the preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet_model = inc_net.InceptionV3(weights=None, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(1, 11):\n",
    "    img_dir = \"img/\" + str(i)\n",
    "    data_path = os.path.join(img_dir,'*g')\n",
    "    files = glob.glob(data_path)\n",
    "    for f1 in files:\n",
    "        img = cv2.imread(f1)\n",
    "        info = np.iinfo(img.dtype) # Get the information of the incoming image type\n",
    "        img = img.astype(np.float64) / info.max # normalize the data to 0 - 1\n",
    "        img = img * 2 - 1\n",
    "        data.append(img)\n",
    "        labels.append(i)\n",
    "\n",
    "rand_order = np.arange(3180)\n",
    "np.random.shuffle(rand_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References: \n",
    "# https://github.com/keras-team/keras/issues/9214\n",
    "# https://keras.io/applications/#usage-examples-for-image-classification-models\n",
    "\n",
    "from keras.applications import resnet50, inception_v3, vgg16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "num_samples = 3180\n",
    "batch_size = 10\n",
    "num_classes = 10\n",
    "num_batches = num_samples // batch_size\n",
    "iteration = 0\n",
    "\n",
    "base_model = inet_model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubPlotter:\n",
    "        \n",
    "    def __init__(self, num_batches):\n",
    "        self.i = 0\n",
    "        self.start = time.time()\n",
    "        self.fig, self.axeslist = plt.subplots(ncols=6, nrows=num_batches, figsize=(96, 96 * num_batches))\n",
    "        \n",
    "    def plot_row(self, imgs, _labels):\n",
    "        for i in range(len(imgs)):\n",
    "            self._plot_two(imgs[i], _labels[i])\n",
    "\n",
    "    def _plot_two(self, img, label):\n",
    "        # Create Explanation\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        # what is this /2+.5 nonsense?!?\n",
    "        expl = explainer.explain_instance(img, model.predict, top_labels=1, hide_color=0, num_samples=1000)\n",
    "        \n",
    "        # Display superpixel mapping\n",
    "        outline = find_boundaries(expl.segments)\n",
    "        c = img.copy()\n",
    "        c[outline] = (1, 1, 0)\n",
    "        _sp = self.axeslist.ravel()[self.i]\n",
    "        _sp.imshow(c / 2 + 0.5, cmap=plt.gray())\n",
    "        _sp.set_axis_off()\n",
    "        self.i += 1\n",
    "        \n",
    "        # Display superpixel contrib\n",
    "        temp, mask = expl.get_image_and_mask(expl.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "        _sp = self.axeslist.ravel()[self.i]\n",
    "        _sp.imshow(mark_boundaries(temp / 2 + 0.5, mask), cmap=plt.gray())\n",
    "        \n",
    "        preds = model.predict(img[np.newaxis,])\n",
    "        label_id = np.argmax(preds) + 1\n",
    "        label_name = column_to_label[label_id]\n",
    "    \n",
    "        _sp.set_axis_off()\n",
    "        self.i += 1\n",
    "        \n",
    "        print(\"Is {}, Predicted {}\".format(column_to_label[label], label_name))\n",
    "        \n",
    "    def print_preds(self, alter_image):\n",
    "        preds = inet_model.predict(np.array([alter_image]))\n",
    "        tup = decode_predictions(preds)[0][0]\n",
    "        print(\"\\noriginal model behavior\")\n",
    "        for x in decode_predictions(preds)[0]:\n",
    "            print(x[1], x[2])\n",
    "            \n",
    "    def add_img(self, img, title):\n",
    "        _sp = self.axeslist.ravel()[self.i]\n",
    "        _sp.imshow(img, cmap=plt.gray())\n",
    "        _sp.set_title(\"num_samples = \" + str(title))\n",
    "        _sp.set_axis_off()\n",
    "        self.i += 1\n",
    "        \n",
    "    def end(self):\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        end = time.time()\n",
    "        diff = end - self.start\n",
    "        print(\"Ran for {} seconds!! ({} minutes)\".format(round(diff, 3), round(diff / 60, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = rand_order[-180:]\n",
    "val_images = np.array([data[index] / 2 + 0.5 for index in selection])\n",
    "val_labels = np.array([labels[index] / 2 + 0.5 for index in selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change input to 53\n",
    "sp = SubPlotter(1)\n",
    "\n",
    "for iteration in range(1):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    \n",
    "    # / 2 + 0.5 gets rid of the nan?!?\n",
    "    x_train_batch = np.array([data[index] / 2 + 0.5 for index in selection])\n",
    "    y_train_batch = np.array([labels[index] / 2 + 0.5 for index in selection])\n",
    "    \n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SubPlotter(53)\n",
    "\n",
    "for iteration in range(53, 106):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    x_train_batch = np.array([data[index] for index in selection])\n",
    "    y_train_batch = np.array([labels[index] for index in selection])\n",
    "\n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SubPlotter(53)\n",
    "\n",
    "for iteration in range(106, 159):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    x_train_batch = np.array([data[index] for index in selection])\n",
    "    y_train_batch = np.array([labels[index] for index in selection])\n",
    "\n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SubPlotter(53)\n",
    "\n",
    "for iteration in range(159, 212):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    x_train_batch = np.array([data[index] for index in selection])\n",
    "    y_train_batch = np.array([labels[index] for index in selection])\n",
    "\n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SubPlotter(53)\n",
    "\n",
    "for iteration in range(212, 265):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    x_train_batch = np.array([data[index] for index in selection])\n",
    "    y_train_batch = np.array([labels[index] for index in selection])\n",
    "\n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SubPlotter(53)\n",
    "\n",
    "for iteration in range(265, 318):\n",
    "    start = iteration * 10\n",
    "    end = (iteration + 1) * 10\n",
    "    selection = rand_order[start: end]\n",
    "    x_train_batch = np.array([data[index] for index in selection])\n",
    "    y_train_batch = np.array([labels[index] for index in selection])\n",
    "\n",
    "    print(str(model.evaluate(x_train_batch, y_train_batch, batch_size=batch_size, verbose=0)) + \"\\n\")\n",
    "    model.fit(x_train_batch, y_train_batch,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_images, val_labels))\n",
    "    \n",
    "    _start = time.time()\n",
    "    sp.plot_row(data[:3], labels[:3])\n",
    "    _end = time.time()\n",
    "    _diff = _end - _start\n",
    "    print(\"Ran for {} seconds!! ({} minutes)\".format(round(_diff, 3), round(_diff / 60, 3)))\n",
    "    \n",
    "sp.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trash Dump"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "num_samples = 1000\n",
    "assert num_samples % 50 == 0\n",
    "\n",
    "num_graphs = num_samples // 10\n",
    "\n",
    "print(\"{:>19}  {:<12}{:>12}  {:<12}{:>12}  {:<12}{:>12}  {:<12}{:>12}  {:<12}\".format(\n",
    "    \"label\", \"score\",\"label\", \"score\",\"label\", \"score\",\"label\", \"score\",\"label\", \"score\"))\n",
    "\n",
    "og_model_behavior = ['American_black_bear', 0.6371611, \n",
    "                     'groenendael', 0.031817913,\n",
    "                     'schipperke', 0.029944215,\n",
    "                     'wombat', 0.028509537,\n",
    "                     'wallaby', 0.025093405]\n",
    "\n",
    "print(\"{:>19}  {:<12}{:>12}  {:<12}{:>12}  {:<12}{:>12}  {:<12}{:>12}  {:<12}\".format(*og_model_behavior))\n",
    "\n",
    "sp = SubPlotter(num_graphs)\n",
    "for iter in range(num_graphs):\n",
    "    num_samples = (iter + 1) * 10\n",
    "    \n",
    "    # Seed entropy\n",
    "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "    explanation = explainer.explain_instance(images[0], inet_model.predict, top_labels=5, hide_color=0, num_samples=num_samples, trace=True)\n",
    "    temp, mask = explanation.get_image_and_mask(295, positive_only=False, num_features=5, hide_rest=False)\n",
    "    img = mark_boundaries(temp / 2 + 0.5, mask)\n",
    "    sp.add_img(img, num_samples)\n",
    "\n",
    "print()\n",
    "sp.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
